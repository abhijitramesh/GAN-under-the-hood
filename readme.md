# Generative Adversarial Networks


# Applications of GANs

---

## StackGan Model

This model takes in a description of a bird and generates a high-resolution image of a bird matching that description. These are images that have not been seen before which means the gan is not searching for an image in a set of images but generates a new image.

## IGAN

These Gan helps artist when a doodle is drawn using a mouse these GANs translate them to images

## Pix2Pix

The GANs take input of an image in one domain and convert them to images in other domains for examples blueprints of building can be changed to images of buildings or drawings of cat can be turned into images of cats.

## Cartoon GANs

These GANs generate cartoon face given a normal face, these GANs were trained on faces of people and cartoon faces but they were not told what image is mapped to what.

## Cycle GANS

These GANs also uses unsupervised learning they can do things like take in a video of a horse and convert it to a video of a zebra , since they are using unsupervised learning they not only convert the horse object but also some parts of the background since they are using unsupervised learning.

## Simulated Training

GANs can take in input of 3d or 2d models and create realistic datasets which can be used as training dataset for image recognition tools.

# How GAN's Work

As we know RNNs can be used for generating text data word by word at a time similarly image can also be generate by fully visible belief networks (what it was called in the 90's) by generating pixel by pixel at a time these are called Autoregressive models (renamed when they were rediscovered later). 

But if we need to generate an entire image as output we use GANs, They consist of two different neural networks called as generators and discriminator.

## Generator

---

The generator is a neural network which takes in a random noise and runs it to a neural network to generate an image this image is *realistic.* The choice of the random noice determine how *realistic* the image is. The generator learns to create these data looking at the data provided.

Unlike a supervised learning model Generative models doesn't have labels to tell what to learn from but they are asked to make more images that come from the same probability distribution.

How do we do this ?

Most generative models do this by adjusting the parameters of the generator but this is difficult to compute this. Most models do this by using some kind of approximations GANs uses some kind of approximations called as Discriminator.

## Discriminator

---

The discriminator is a normal classifier neural net which predicts if the image generated by the generator is real or fake, if it is real the generator will give a value close to one if not otherwise.

Overtime generator tries to make images which have probability close to one and discriminator gets better and better at determining which images are not real.

# Games and Equilibria

# Game Theory

For an generative adversarial network the Generator and the Discriminator are in competition with each other. In order to understand this competition we use Game theory.

Game theory defines co-operation and conflict between rational agents in any situation where each agents can choose from a set of actions and every action has a well defined payoff for each player.

# Rock-Paper-Scissors

Each player can choose to play Rock, Paper or Scissors this defines a set of actions.

Each player is also associated with a payoff

The winning player receives a payoff of +1

The loosing player receives a payoff of -1

and if both players chooses to play the same they both receive a payoff of 0

## The basic rule

rock smashes scissors, scissors cut paper and paper covers rock.

## The IDEA

Suppose that player one always plays scissors and player two always play rock this means player one always looses and player two always wins. Player one can improve the strategy by playing scissors more often. 

If the players are allowed to randomise there moves they will eventually go to equilibrium where neither player can improve there payoff by improving there strategy.

Lets consider that player two chooses rock,paper or scissors uniformly at random.

If player one increases his strategy by increasing the time he plays rock this would increase the chance of winning for player one but at the same time if player two plays scissors for the same amount of increased time then this would cancel out the wins of player one.

This gives basic understanding of Game theory and tells us that rational agents can learn to play completely at random.

## Applying this to GANs

If we can understand the equilibrium of the ROCK-PAPER-SCISSOR game we can apply this to the GAN game we can use this as a defining character for training GANs.

Most ML models are based on Optimisation

we write down the cost function of the algorithm, we visualise this and try to minimise this losses.

The goal of the algorithm is to reach a local minima or a minima but this does not usually happen due to some arithmetic limits.

For GANs the two different players the Generator and the Discriminator both have there own costs.

The generator wants to minimise the value function and the discriminator wants to maximise the value functions.
